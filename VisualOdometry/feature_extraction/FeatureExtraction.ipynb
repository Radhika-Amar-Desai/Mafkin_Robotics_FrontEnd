{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import shutil\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import ResNet50_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to C:\\Users\\97433/.cache\\torch\\hub\\checkpoints\\resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:35<00:00, 2.90MB/s]\n"
     ]
    }
   ],
   "source": [
    "resnet_model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "resnet_model.eval()\n",
    "resnet_model = torch.nn.Sequential(*(list(resnet_model.children())[:-1]))\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                        std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax ( x : float ) -> float: \n",
    "    \"\"\"\n",
    "        Returns output after applying softmax function on input x. \n",
    "    \"\"\"\n",
    "    return np.exp ( x ) / np.sum ( np.exp ( x ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_feat_vec ( image_path : str, \n",
    "                  transform = transform,\n",
    "                  model = resnet_model):\n",
    "    \"\"\"\n",
    "        Returns a feature vector for the image stored \n",
    "        at image path using pretrained model.\n",
    "    \"\"\"\n",
    "    image = Image.open ( image_path )\n",
    "    input_image = transform(image).unsqueeze(0)  \n",
    "    with torch.no_grad():\n",
    "        output = model(input_image)\n",
    "    feat_vec_as_np_array = output.squeeze().numpy()\n",
    "    normalized_feat_vec_as_np_array = softmax ( feat_vec_as_np_array )\n",
    "    return normalized_feat_vec_as_np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity_between_vectors ( first_feat_vec : list,\n",
    "                                        second_feat_vec : list ) -> float:\n",
    "    \"\"\"\n",
    "        Returns cosine similarity score between two feature vectors.\n",
    "    \"\"\"\n",
    "    return 1 - spatial.distance.cosine( first_feat_vec, second_feat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_euclidean_distance ( first_feat_vec : list, \n",
    "                            second_feat_vec : list ) -> float:\n",
    "    \"\"\"\n",
    "        Returns euclidean distance between two feature vectors.\n",
    "    \"\"\"\n",
    "    return spatial.distance.euclidean ( first_feat_vec, second_feat_vec )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity_score ( first_image_path : str , second_image_path : str,\n",
    "                                transform = transform , model = resnet_model ) -> float:\n",
    "    \"\"\"\n",
    "        Returns cosine similarity score between two images based \n",
    "        on their feature vectors obatined from pretrained models.\n",
    "    \"\"\"    \n",
    "    first_image_feat_vec = get_normalized_feat_vec ( first_image_path , transform , model )\n",
    "    second_image_feat_vec = get_normalized_feat_vec ( second_image_path , transform , model )\n",
    "\n",
    "    return get_cosine_similarity_between_vectors ( first_image_feat_vec, \n",
    "                                                  second_image_feat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_euclidean_dissimilarity_score ( first_image_path : str , second_image_path : str ,\n",
    "                            transform = transform , model = resnet_model ) -> float:\n",
    "    \"\"\"\n",
    "        Returns dissimilarity score between two images based on the euclidean distance \n",
    "        between their feature vectors obatined from pretrained models.\n",
    "    \"\"\"    \n",
    "    first_image_feat_vec = get_normalized_feat_vec ( first_image_path , transform , model )\n",
    "    second_image_feat_vec = get_normalized_feat_vec ( second_image_path ,transform , model )\n",
    "\n",
    "    return get_euclidean_distance ( first_image_feat_vec , second_image_feat_vec )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = r\"C:\\Users\\97433\\Mafkin_Robotics_FrontEnd\\VisualOdometry\\feature_extraction\\dataset\\blobs\\image_pair1\\blob0\\image2\\blob_at_2448_1924_image_2.jpg\"\n",
    "image2 = r\"C:\\Users\\97433\\Mafkin_Robotics_FrontEnd\\VisualOdometry\\feature_extraction\\dataset\\blobs\\image_pair1\\blob0\\image1\\blob_at_1573_2187_image_1.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image ( image : list, border_len = 1 ):\n",
    "    \"\"\"\n",
    "        Pads image with 0s such that length and height\n",
    "        of image increase by border_len.\n",
    "    \"\"\"\n",
    "    return np.pad ( image , border_len, mode = \"constant\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_vec( data : list, min_val : int, max_val : int) -> list:\n",
    "    \"\"\"\n",
    "    Perform Min-Max normalization on the input data.\n",
    "\n",
    "    Parameters:\n",
    "    - data: A numpy array or list containing the data to be normalized.\n",
    "\n",
    "    Returns:\n",
    "    - normalized_data: The normalized data.\n",
    "    \"\"\"\n",
    "\n",
    "    normalized_data = (data - min_val) / (max_val - min_val)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize ( x : int, min_val : int, max_val : int ) -> int:\n",
    "    return ( x - min_val ) / ( max_val - min_val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blob(image : list, key_point : tuple , blob_size : tuple):\n",
    "    \"\"\"\n",
    "    Extracts a patch (blob) from the image centered at the key_point\n",
    "    with the specified blob_size (height, width).\n",
    "\n",
    "    Args:\n",
    "    - image: The input image.\n",
    "    - key_point: The key point (x, y) around which the blob is extracted.\n",
    "    - blob_size: The size of the blob in pixels (height, width).\n",
    "\n",
    "    Returns:\n",
    "    - blob_patch: The extracted patch (blob) from the image.\n",
    "    \"\"\"\n",
    "\n",
    "    kp_x, kp_y = int(key_point[0]), int(key_point[1])\n",
    "\n",
    "    blob_height, blob_width = blob_size\n",
    "\n",
    "    top_left_x = max(0, kp_x - blob_width // 2)\n",
    "    top_left_y = max(0, kp_y - blob_height // 2)\n",
    "\n",
    "    bottom_right_x = min(image.shape[1], kp_x + blob_width // 2)\n",
    "    bottom_right_y = min(image.shape[0], kp_y + blob_height // 2)\n",
    "\n",
    "    blob_patch = image[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "\n",
    "    return blob_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blob_sequence_at_point ( image : list, coord : tuple, \n",
    "                               blob_sizes = [ 10, 25, 50, 100 ] ) -> list:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - image (list): Image from which squence of blobs is to be generated.\n",
    "    - coord (tuple): A tuple containing the (x, y) coordinate of the center of each blob.\n",
    "    - blob_sizes (list): Sizes of blobs of the sequence.\n",
    "    Returns:\n",
    "    - blob_sequence (list): A list containing the blobs.\n",
    "                            Each blob is represented as a square patch\n",
    "                            of the specified size with its center\n",
    "                            as given by the center_coordinates.\n",
    "    \"\"\"\n",
    "    return [ get_blob ( image, coord, ( blob_size, blob_size)) \\\n",
    "            for blob_size in blob_sizes ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_keypoints( first_image_path : list, second_image_path : list) -> list:\n",
    "    \"\"\" \n",
    "        Returns list of corresponding keypoints in both images sing ORB_FLANN feature matching.\n",
    "    \"\"\" \n",
    "    first_image = cv2.imread ( first_image_path , 0 )\n",
    "    second_image = cv2.imread ( second_image_path , 0 )\n",
    "    \n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    first_image_keypoints, first_descriptors = orb.detectAndCompute( first_image , None)\n",
    "    second_image_keypoints, second_descriptors = orb.detectAndCompute( second_image , None)\n",
    "\n",
    "    FLANN_INDEX_LSH = 6\n",
    "    index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "    search_params = dict(checks=50)  \n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    matches = flann.knnMatch( first_descriptors, second_descriptors, k=2)\n",
    "\n",
    "    good_matches = []\n",
    "    for match_pair in matches:\n",
    "        if len(match_pair) < 2:\n",
    "            continue\n",
    "        m , n = match_pair\n",
    "        if m.distance < 0.7 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    first_image_matched_keypoints = [ (int(first_image_keypoints[match.queryIdx].pt[0]) ,\n",
    "                                      int(first_image_keypoints[match.queryIdx].pt[1]))  \\\n",
    "                                    for match in good_matches]\n",
    "    second_image_matched_keypoints = [ (int(second_image_keypoints[match.trainIdx].pt[0]),\n",
    "                                        int(second_image_keypoints[match.trainIdx].pt[1])) \\\n",
    "                                      for match in good_matches]\n",
    "\n",
    "    return [ [keypoint, second_image_matched_keypoints[index] ] \\\n",
    "            for index,keypoint in enumerate ( first_image_matched_keypoints )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_matching_keypoints ( first_image_path : str, second_image_path : str ) -> list:\n",
    "    \"\"\"\n",
    "        Returns corresponding keypoints between two images.\n",
    "    \"\"\"\n",
    "    orb_keypoints = get_matching_keypoints ( first_image_path, second_image_path )\n",
    "    return [ [ first_image_keypoint[ 0 ], orb_keypoints [::-1] [ index ][ 1 ]] \\\n",
    "            for index, first_image_keypoint in enumerate ( orb_keypoints ) \n",
    "            if first_image_keypoint[ 1 ] != orb_keypoints [ ::-1 ][ index ][ 1 ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_matching_keypoints_blob_sequences ( folder_to_save : str, \n",
    "                                            image_pair_folder : str,\n",
    "                                            generate_keypoints_func : str,\n",
    "                                            generate_blob_sequence_func = get_blob_sequence_at_point,\n",
    "                                            extended_name_of_blob_sequence_folder = None) -> None:\n",
    "    \"\"\"\n",
    "        Functionality : \n",
    "        - Saves blob sequence consisting of blobs of various sizes having keypoints as center\n",
    "        for both images in the specified image pair folder. \n",
    "        \n",
    "        Parameters : \n",
    "        - folder_to_save : folder path to save blob_sequence.\n",
    "        - image_pair_folder : folder path for image pair.\n",
    "        - generate_keypoints_function : function used to generate keypoints.\n",
    "        - generate_blob_sequence_func : function used to generate blob sequence.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.join ( folder_to_save ): os.makedirs ( folder_to_save )\n",
    "\n",
    "    first_image_path, second_image_path =\\\n",
    "        [ os.path.join ( image_pair_folder, image )\\\n",
    "        for image in os.listdir( image_pair_folder ) ]\n",
    "    \n",
    "    list_of_keypoints = generate_keypoints_func ( first_image_path, second_image_path )\n",
    "\n",
    "    first_image = cv2.imread ( first_image_path )\n",
    "    second_image = cv2.imread ( second_image_path )\n",
    "\n",
    "    blob_sequences_for_first_image = [ generate_blob_sequence_func ( first_image, keypoint[0] )\\\n",
    "                                      for keypoint in list_of_keypoints ]\n",
    "    \n",
    "    blob_sequences_for_second_image = [ generate_blob_sequence_func ( second_image, keypoint[1] )\\\n",
    "                                      for keypoint in list_of_keypoints ]\n",
    "\n",
    "    for index, blob_sequence in enumerate ( blob_sequences_for_first_image ):\n",
    "        blob_sequence_folder_name = \"blob_sequence_\" + str ( index ) + extended_name_of_blob_sequence_folder\n",
    "        blob_sequence_folder_path = os.path.join ( folder_to_save, blob_sequence_folder_name )\n",
    "        \n",
    "        if not os.path.exists ( blob_sequence_folder_path ): os.makedirs ( blob_sequence_folder_path )\n",
    "\n",
    "        first_image_blob_sequence_folder_path = os.path.join ( blob_sequence_folder_path, \"image1\" )\n",
    "        second_image_blob_sequence_folder_path = os.path.join ( blob_sequence_folder_path, \"image2\" )\n",
    "\n",
    "        if not os.path.exists ( first_image_blob_sequence_folder_path ): \n",
    "            os.makedirs ( first_image_blob_sequence_folder_path )\n",
    "\n",
    "        if not os.path.exists ( second_image_blob_sequence_folder_path ):\n",
    "            os.makedirs ( second_image_blob_sequence_folder_path )\n",
    "\n",
    "        for blob_index, blob_image in enumerate ( blob_sequence ):\n",
    "\n",
    "            blob_image_name = \"blob\" + str(blob_index) + \".jpg\"\n",
    "            \n",
    "            blob_image_path = os.path.join ( first_image_blob_sequence_folder_path, \n",
    "                                                        blob_image_name )\n",
    "            cv2.imwrite ( blob_image_path, blob_image )\n",
    "\n",
    "    \n",
    "        for blob_index, blob_image in enumerate ( blob_sequences_for_second_image [ index ] ):\n",
    "\n",
    "            blob_image_name = \"blob\" + str(blob_index) + \".jpg\"\n",
    "            \n",
    "            blob_image_path = os.path.join ( second_image_blob_sequence_folder_path, \n",
    "                                                        blob_image_name )\n",
    "            cv2.imwrite ( blob_image_path, blob_image )\n",
    "    print ( \"Done :)\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_save_matching_keypoints_blob_sequences ( folder_to_save : str, \n",
    "                                            folder_containing_image_pairs : str,\n",
    "                                            generate_keypoints_func : str,\n",
    "                                            generate_blob_sequence_func = get_blob_sequence_at_point ) -> None:\n",
    "    \"\"\"\n",
    "        Functionality : \n",
    "        - Saves blob sequence consisting of blobs of various sizes having specified keypoints as center\n",
    "        for images of image pairs in the specified folder. \n",
    "        \n",
    "        Parameters : \n",
    "        - folder_to_save : folder path to save blob_sequence.\n",
    "        - folder_containing_image_pairs : folder path containing image pairs.\n",
    "        - generate_keypoints_func : function used to generate keypoints.\n",
    "        - generate_blob_sequence_func : function used to generate blob sequence.\n",
    "    \"\"\"\n",
    "    if not os.path.exists ( folder_to_save ): os.makedirs ( folder_to_save )\n",
    "\n",
    "    for index, image_pair_folder in enumerate ( os.listdir ( folder_containing_image_pairs ) ):\n",
    "        \n",
    "        image_pair_folder_path = os.path.join ( folder_containing_image_pairs, image_pair_folder )\n",
    "        \n",
    "        # image_pair_folder_to_save_blob_sequence = \"image_pair\" + str(index)\n",
    "        \n",
    "        # image_pair_folder_to_save_blob_sequence_path = os.path.join ( folder_to_save,\n",
    "        #                                                             image_pair_folder_to_save_blob_sequence )\n",
    "        \n",
    "        # if not os.path.exists ( image_pair_folder_to_save_blob_sequence_path ):\n",
    "        #     os.makedirs ( image_pair_folder_to_save_blob_sequence_path )\n",
    "\n",
    "        extended_name_of_blob_sequence_folder = \"_image_pair\" + str(index)\n",
    "\n",
    "        save_matching_keypoints_blob_sequences ( folder_to_save = folder_to_save,\n",
    "                                                image_pair_folder = image_pair_folder_path,\n",
    "                                                generate_blob_sequence_func = generate_blob_sequence_func,\n",
    "                                                generate_keypoints_func = generate_keypoints_func,\n",
    "                                                extended_name_of_blob_sequence_folder = \\\n",
    "                                                    extended_name_of_blob_sequence_folder)\n",
    "\n",
    "    print ( \"Done :)\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset ( root_dir : str ) -> None:\n",
    "    \"\"\" \n",
    "        Balances dataset consisting of two classes by : \n",
    "        - removing additional files from class containing maximum number of files if difference \n",
    "        between number of files in both classes is less than 10. \n",
    "    \"\"\"\n",
    "    class_folder_paths = [ os.path.join ( root_dir, class_folder_name ) \\\n",
    "                          for class_folder_name in os.listdir ( root_dir ) ]\n",
    "    \n",
    "    class_folder_and_number_of_files = { class_folder_path : len(os.listdir( class_folder_path ))\\\n",
    "                                        for class_folder_path in class_folder_paths }\n",
    "    \n",
    "    sorted_class_folder_list = sorted ( class_folder_and_number_of_files, \n",
    "                                       key = class_folder_and_number_of_files.get )\n",
    "    \n",
    "    diff_in_number_of_files_in_classes = len ( os.listdir ( sorted_class_folder_list[1] ) ) - len ( os.listdir ( sorted_class_folder_list[0] ) )\n",
    "\n",
    "    if diff_in_number_of_files_in_classes < 20:\n",
    "        \n",
    "        majority_class_folder_path = sorted_class_folder_list [ 1 ]\n",
    "        \n",
    "        folders_in_majority_class =\\\n",
    "            [ os.path.join ( majority_class_folder_path, sub_folder ) \\\n",
    "            for sub_folder in os.listdir ( majority_class_folder_path )]\n",
    "    \n",
    "        folders_to_delete = random.sample(folders_in_majority_class, \n",
    "                                        min( diff_in_number_of_files_in_classes, \n",
    "                                            len(folders_in_majority_class)))\n",
    "\n",
    "        print ( len ( folders_to_delete ) )\n",
    "\n",
    "        for folder in folders_to_delete:\n",
    "            folder_path = os.path.join( majority_class_folder_path , folder)\n",
    "            shutil.rmtree ( folder_path )\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_blob_sequence_dataset ( Dataset ):\n",
    "    \n",
    "    def __init__(self, root_dir : str, blob_index: int) -> None:\n",
    "        self.root_dir = root_dir\n",
    "        self.blob_index = blob_index\n",
    "        self.transform = transforms.Compose([ transforms.Resize((224, 224)),  transforms.ToTensor() ])\n",
    "\n",
    "    def __len__ ( self ) -> int:\n",
    "        \n",
    "        class_folders = [ os.path.join ( self.root_dir, class_folder ) \\\n",
    "                        for class_folder in os.listdir ( self.root_dir ) ]\n",
    "        \n",
    "        return len ( os.listdir ( class_folders [ 0 ] ) ) + len ( os.listdir ( class_folders [ 1 ] ) )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        class_folders = [ os.path.join ( self.root_dir, class_folder ) \\\n",
    "                        for class_folder in os.listdir ( self.root_dir ) ]\n",
    "        \n",
    "        blob_sequences = sorted([ os.path.join ( class_folder, blob_sequence_folder ) \\\n",
    "                            for class_folder in class_folders \\\n",
    "                            for blob_sequence_folder in os.listdir ( class_folder ) ])\n",
    "        \n",
    "        labels = [ 1 if \"dissimilar\" == blob_sequence.split(\"\\\\\")[-2] else 0 \\\n",
    "                for blob_sequence in blob_sequences  ]\n",
    "        \n",
    "        images_folder = [ os.path.join ( blob_sequences[ index ], image ) \\\n",
    "                        for image in os.listdir(blob_sequences[index]) ]\n",
    "        \n",
    "        blob_images = [os.path.join ( images_folder[0], os.listdir ( images_folder[0] )[self.blob_index] ),\n",
    "                       os.path.join ( images_folder[1], os.listdir(images_folder[1])[self.blob_index] )]\n",
    "        \n",
    "        if self.transform:\n",
    "            blob_images = [ self.transform ( Image.open(blob_image) )\\\n",
    "                            for blob_image in blob_images ]\n",
    "\n",
    "        return blob_images[ 0 ], blob_images[1] , labels [ index ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomResNet ( nn.Module ) :\n",
    "    def __init__( self , num_classes , pretrained = True ):\n",
    "        super ( CustomResNet, self ).__init__()\n",
    "        \n",
    "        # Load pretrained ResNet50 model\n",
    "        self.resnet = models.resnet50( weights = ResNet50_Weights.DEFAULT )\n",
    "        \n",
    "        # Freeze convolutional layers if using pretrained weights\n",
    "        if pretrained:\n",
    "            for param in self.resnet.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        # Replace the last fully connected layer\n",
    "        num_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Sequential ( nn.Linear ( num_features, 512 ), nn.ReLU(), \n",
    "                                        nn.Dropout ( 0.5 ), nn.Linear ( 512, num_classes ))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetwork(nn.Module):\n",
    "    def __init__(self, num_classes = 10):\n",
    "        super(SiameseNetwork, self).__init__()\n",
    "        \n",
    "        # Define the architecture for each subnetwork (or branch)\n",
    "        self.subnetwork1 = CustomResNet(num_classes)\n",
    "        self.subnetwork2 = CustomResNet(num_classes)\n",
    "        \n",
    "    def forward(self, input1, input2):\n",
    "        # Forward pass through both branches\n",
    "        output1 = self.subnetwork1(input1)\n",
    "        output2 = self.subnetwork2(input2)\n",
    "        return output1, output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLoss(torch.nn.Module):\n",
    "    def __init__(self, margin=2.0):\n",
    "        super(ContrastiveLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "\n",
    "    def forward(self, output1, output2, label):\n",
    "      # Calculate the euclidian distance and calculate the contrastive loss\n",
    "      euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)\n",
    "\n",
    "      loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
    "                                    (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
    "\n",
    "\n",
    "      return loss_contrastive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train( root_dir, index):\n",
    "    model = SiameseNetwork()\n",
    "\n",
    "    counter = []\n",
    "    loss_history = []\n",
    "    iteration_number= 0\n",
    "\n",
    "    criterion = ContrastiveLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr = 0.001 )\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    trainDS = custom_blob_sequence_dataset( root_dir, index)\n",
    "    train_dataloader = DataLoader ( trainDS, batch_size = 1, shuffle = False, pin_memory = True)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        epoch_loss = 0.0\n",
    "        # Iterate over batches\n",
    "        for i, (img0, img1, label) in enumerate(train_dataloader):\n",
    "\n",
    "            # Send the images and labels to CUDA\n",
    "            #print ( img0 )\n",
    "            img0, img1, label = img0.to(device), img1.to(device), label.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Pass in the two images into the network and obtain two outputs\n",
    "            output1, output2 = model(img0, img1)\n",
    "            # Pass the outputs of the networks and label into the loss function\n",
    "            loss_contrastive = criterion(output1, output2, label)\n",
    "\n",
    "            epoch_loss += loss_contrastive.item()\n",
    "\n",
    "            # Calculate the backpropagation\n",
    "            loss_contrastive.backward()\n",
    "\n",
    "            # Optimize\n",
    "            optimizer.step()\n",
    "\n",
    "            # Every 10 batches print out the loss\n",
    "            if i % 10 == 0 :\n",
    "                print(f\"Epoch number {epoch} Bacth number{i} Current loss {loss_contrastive.item()}\\n\")\n",
    "                iteration_number += 10\n",
    "\n",
    "                counter.append(iteration_number)\n",
    "                loss_history.append(loss_contrastive.item())\n",
    "    \n",
    "        avg_epoch_loss = epoch_loss / len ( train_dataloader )\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/100], Average Loss: {avg_epoch_loss}\")\n",
    "\n",
    "    print ( \"Training Completed.\" )\n",
    "    model_name = \"model\" + str(index)\n",
    "    print ( \"Saving Model.\" )\n",
    "    torch.save ( model, model_name )\n",
    "    print ( \"Model saved.\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number 0 Bacth number0 Current loss 3.342322587966919\n",
      "\n",
      "Epoch number 0 Bacth number10 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number20 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number30 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number40 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number50 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number60 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number70 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number80 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number90 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number100 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number110 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number120 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number130 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number140 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number150 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number160 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number170 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number180 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number190 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number200 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number210 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number220 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number230 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number240 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number250 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number260 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number270 Current loss 0.0\n",
      "\n",
      "Epoch number 0 Bacth number280 Current loss 56.327762603759766\n",
      "\n",
      "Epoch number 0 Bacth number290 Current loss 3.245903730392456\n",
      "\n",
      "Epoch number 0 Bacth number300 Current loss 1.8820761442184448\n",
      "\n",
      "Epoch number 0 Bacth number310 Current loss 3.5878517627716064\n",
      "\n",
      "Epoch number 0 Bacth number320 Current loss 3.7343244552612305\n",
      "\n",
      "Epoch number 0 Bacth number330 Current loss 6.008617401123047\n",
      "\n",
      "Epoch number 0 Bacth number340 Current loss 2.8250224590301514\n",
      "\n",
      "Epoch number 0 Bacth number350 Current loss 0.36722061038017273\n",
      "\n",
      "Epoch number 0 Bacth number360 Current loss 0.2783096730709076\n",
      "\n",
      "Epoch number 0 Bacth number370 Current loss 0.6037214994430542\n",
      "\n",
      "Epoch number 0 Bacth number380 Current loss 0.0821399837732315\n",
      "\n",
      "Epoch number 0 Bacth number390 Current loss 0.15511849522590637\n",
      "\n",
      "Epoch number 0 Bacth number400 Current loss 0.3950560688972473\n",
      "\n",
      "Epoch number 0 Bacth number410 Current loss 0.040448226034641266\n",
      "\n",
      "Epoch number 0 Bacth number420 Current loss 0.020301658660173416\n",
      "\n",
      "Epoch number 0 Bacth number430 Current loss 0.2919432818889618\n",
      "\n",
      "Epoch number 0 Bacth number440 Current loss 0.01602013036608696\n",
      "\n",
      "Epoch number 0 Bacth number450 Current loss 0.02143103815615177\n",
      "\n",
      "Epoch number 0 Bacth number460 Current loss 0.09386111050844193\n",
      "\n",
      "Epoch number 0 Bacth number470 Current loss 0.010772367008030415\n",
      "\n",
      "Epoch number 0 Bacth number480 Current loss 0.0034711151383817196\n",
      "\n",
      "Epoch number 0 Bacth number490 Current loss 0.0013075240422040224\n",
      "\n",
      "Epoch number 0 Bacth number500 Current loss 0.01630202680826187\n",
      "\n",
      "Epoch number 0 Bacth number510 Current loss 0.004387508146464825\n",
      "\n",
      "Epoch number 0 Bacth number520 Current loss 0.015034496784210205\n",
      "\n",
      "Epoch number 0 Bacth number530 Current loss 0.0078755347058177\n",
      "\n",
      "Epoch number 0 Bacth number540 Current loss 0.006484648212790489\n",
      "\n",
      "Epoch number 0 Bacth number550 Current loss 0.006114209536463022\n",
      "\n",
      "Epoch [1/100], Average Loss: 1.1353883936435065\n",
      "Epoch number 1 Bacth number0 Current loss 3.740966558456421\n",
      "\n",
      "Epoch number 1 Bacth number10 Current loss 2.810344696044922\n",
      "\n",
      "Epoch number 1 Bacth number20 Current loss 0.0\n",
      "\n",
      "Epoch number 1 Bacth number30 Current loss 0.0\n",
      "\n",
      "Epoch number 1 Bacth number40 Current loss 0.0\n",
      "\n",
      "Epoch number 1 Bacth number50 Current loss 0.0\n",
      "\n",
      "Epoch number 1 Bacth number60 Current loss 0.0\n",
      "\n",
      "Epoch number 1 Bacth number70 Current loss 0.0\n",
      "\n",
      "Epoch number 1 Bacth number80 Current loss 0.0\n",
      "\n",
      "Epoch number 1 Bacth number90 Current loss 0.0\n",
      "\n",
      "Epoch number 1 Bacth number100 Current loss 0.0\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[94], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m97433\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mMafkin_Robotics_FrontEnd\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mVisualOdometry\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mfeature_extraction\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdataset_for_ANN\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[93], line 29\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(root_dir, index)\u001b[0m\n\u001b[0;32m     26\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Pass in the two images into the network and obtain two outputs\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m output1, output2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Pass the outputs of the networks and label into the loss function\u001b[39;00m\n\u001b[0;32m     31\u001b[0m loss_contrastive \u001b[38;5;241m=\u001b[39m criterion(output1, output2, label)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[82], line 11\u001b[0m, in \u001b[0;36mSiameseNetwork.forward\u001b[1;34m(self, input1, input2)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input1, input2):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Forward pass through both branches\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     output1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubnetwork1\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     output2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubnetwork2(input2)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output1, output2\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[81], line 19\u001b[0m, in \u001b[0;36mCustomResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\resnet.py:276\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[0;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[1;32m--> 276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[0;32m    279\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\resnet.py:146\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    144\u001b[0m     identity \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m--> 146\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(out)\n\u001b[0;32m    148\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train( r\"C:\\Users\\97433\\Mafkin_Robotics_FrontEnd\\VisualOdometry\\feature_extraction\\dataset_for_ANN\\train\",0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_training_and_testing_folders ( root_dir : str, train_test_split = 0.15 ) -> None:\n",
    "    \"\"\" \n",
    "        Splits the root directory into train and test folders.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_folder = os.path.join ( root_dir , \"train\" )\n",
    "    test_folder = os.path.join ( root_dir , \"test\" )\n",
    "\n",
    "    for class_folder in os.listdir ( root_dir ):\n",
    "\n",
    "        if class_folder == \"train\" or class_folder == \"test\":\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists ( train_folder ): os.makedirs ( train_folder )\n",
    "        if not os.path.exists ( test_folder ): os.makedirs ( test_folder )\n",
    "\n",
    "        train_class_folder = os.path.join ( train_folder , class_folder )\n",
    "        test_class_folder = os.path.join ( test_folder , class_folder )\n",
    "\n",
    "        if not os.path.exists ( train_class_folder ):\n",
    "            os.makedirs ( train_class_folder )\n",
    "\n",
    "        if not os.path.exists ( test_class_folder ):\n",
    "            os.makedirs ( test_class_folder )\n",
    "\n",
    "        class_folder_path = os.path.join ( root_dir, class_folder )\n",
    "\n",
    "        blob_sequence_folder_paths = [ os.path.join ( class_folder_path, blob_sequence_folder ) \\\n",
    "                                    for blob_sequence_folder in os.listdir ( class_folder_path ) ]\n",
    "        \n",
    "        train_test_split_index = int ( len ( blob_sequence_folder_paths ) * train_test_split )\n",
    "        \n",
    "        test_data = blob_sequence_folder_paths [ : train_test_split_index ]\n",
    "        train_data = blob_sequence_folder_paths [ train_test_split_index : ]\n",
    "\n",
    "        for train_data_path in train_data:\n",
    "            shutil.move ( train_data_path , train_class_folder )\n",
    "        \n",
    "        for test_data_path in test_data:\n",
    "            shutil.move ( test_data_path , test_class_folder  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = r\"C:\\Users\\97433\\Mafkin_Robotics_FrontEnd\\VisualOdometry\\feature_extraction\\dataset_for_ANN\\train\"\n",
    "test_directory = r\"C:\\Users\\97433\\Mafkin_Robotics_FrontEnd\\VisualOdometry\\feature_extraction\\dataset_for_ANN\\test\"\n",
    "\n",
    "train_DS = custom_blob_sequence_dataset ( root_dir = train_directory )\n",
    "test_DS = custom_blob_sequence_dataset ( root_dir = test_directory )\n",
    "\n",
    "train_loader = DataLoader ( train_DS , batch_size = 4 , shuffle = True )\n",
    "test_loader = DataLoader ( test_DS , batch_size = 4 , shuffle = True  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceClassifier ( nn.Module ) :\n",
    "    def __init__ ( self ) :\n",
    "        super ( SequenceClassifier , self ).__init__()\n",
    "        self.fc1 = nn.Linear ( 4 , 16 ).float ()\n",
    "        self.fc2 = nn.Linear ( 16 , 8 ).float ()\n",
    "        self.fc3 = nn.Linear ( 8 , 1 ).float ()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu ( self.fc1( x ) )\n",
    "        x = torch.relu ( self.fc2( x ) )\n",
    "        x = torch.sigmoid( self.fc3( x ) )  \n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
