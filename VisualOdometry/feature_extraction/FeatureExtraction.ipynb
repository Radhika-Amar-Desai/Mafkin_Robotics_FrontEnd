{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import shutil\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\97433\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\97433\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet_model = models.resnet50(pretrained=True)\n",
    "resnet_model.eval()\n",
    "resnet_model = torch.nn.Sequential(*(list(resnet_model.children())[:-1]))\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                        std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax ( x : float ) -> float: \n",
    "    \"\"\"\n",
    "        Returns output after applying softmax function on input x. \n",
    "    \"\"\"\n",
    "    return np.exp ( x ) / np.sum ( np.exp ( x ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_feat_vec ( image_path : str, \n",
    "                  transform = transform,\n",
    "                  model = resnet_model):\n",
    "    \"\"\"\n",
    "        Returns a feature vector for the image stored \n",
    "        at image path using pretrained model.\n",
    "    \"\"\"\n",
    "    image = Image.open ( image_path )\n",
    "    input_image = transform(image).unsqueeze(0)  \n",
    "    with torch.no_grad():\n",
    "        output = model(input_image)\n",
    "    feat_vec_as_np_array = output.squeeze().numpy()\n",
    "    normalized_feat_vec_as_np_array = softmax ( feat_vec_as_np_array )\n",
    "    return normalized_feat_vec_as_np_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity_between_vectors ( first_feat_vec : list,\n",
    "                                        second_feat_vec : list ) -> float:\n",
    "    \"\"\"\n",
    "        Returns cosine similarity score between two feature vectors.\n",
    "    \"\"\"\n",
    "    return 1 - spatial.distance.cosine( first_feat_vec, second_feat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_euclidean_distance ( first_feat_vec : list, \n",
    "                            second_feat_vec : list ) -> float:\n",
    "    \"\"\"\n",
    "        Returns euclidean distance between two feature vectors.\n",
    "    \"\"\"\n",
    "    return spatial.distance.euclidean ( first_feat_vec, second_feat_vec )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity_score ( first_image_path : str , second_image_path : str,\n",
    "                                transform = transform , model = resnet_model ) -> float:\n",
    "    \"\"\"\n",
    "        Returns cosine similarity score between two images based \n",
    "        on their feature vectors obatined from pretrained models.\n",
    "    \"\"\"    \n",
    "    first_image_feat_vec = get_normalized_feat_vec ( first_image_path , transform , model )\n",
    "    second_image_feat_vec = get_normalized_feat_vec ( second_image_path , transform , model )\n",
    "\n",
    "    return get_cosine_similarity_between_vectors ( first_image_feat_vec, \n",
    "                                                  second_image_feat_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_histogram_dissimilarity_score ( first_feat_vec, second_feat_vec ):\n",
    "    return sum(abs((first_feat_vec - second_feat_vec) / ( 1 + first_feat_vec + second_feat_vec )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_euclidean_dissimilarity_score ( first_image_path : str , second_image_path : str ,\n",
    "                            transform = transform , model = resnet_model ) -> float:\n",
    "    \"\"\"\n",
    "        Returns dissimilarity score between two images based on the euclidean distance \n",
    "        between their feature vectors obatined from pretrained models.\n",
    "    \"\"\"    \n",
    "    first_image_feat_vec = get_normalized_feat_vec ( first_image_path , transform , model )\n",
    "    second_image_feat_vec = get_normalized_feat_vec ( second_image_path ,transform , model )\n",
    "\n",
    "    return get_euclidean_distance ( first_image_feat_vec , second_image_feat_vec )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = r\"C:\\Users\\97433\\Mafkin_Robotics_FrontEnd\\VisualOdometry\\feature_extraction\\dataset\\blobs\\image_pair1\\blob0\\image2\\blob_at_2448_1924_image_2.jpg\"\n",
    "image2 = r\"C:\\Users\\97433\\Mafkin_Robotics_FrontEnd\\VisualOdometry\\feature_extraction\\dataset\\blobs\\image_pair1\\blob0\\image1\\blob_at_1573_2187_image_1.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image ( image : list, border_len = 1 ):\n",
    "    \"\"\"\n",
    "        Pads image with 0s such that length and height\n",
    "        of image increase by border_len.\n",
    "    \"\"\"\n",
    "    return np.pad ( image , border_len, mode = \"constant\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def F1( intensity : int):\n",
    "    return int ( intensity >= 0 )\n",
    "\n",
    "def F3 ( k1 : int, k2 : int ):\n",
    "    is_k1_non_negative = k1 >= 0\n",
    "    is_k2_non_negative = k2 >= 0\n",
    "\n",
    "    return ~(is_k1_non_negative ^ is_k2_non_negative) & 1\n",
    "\n",
    "def labeled_coord_of_patch ( n : int, x : int , y : int ):\n",
    "    \"\"\"\n",
    "        Returns coordinates (x,y) of image according to \n",
    "        label number n\n",
    "    \"\"\"\n",
    "    try:\n",
    "        labeled_coords = [(0,0), (0,1), (1,1), \n",
    "                          (1,0), (1,-1), (0,-1), \n",
    "                          (-1,-1), (-1,0), (-1,1) ]\n",
    "        coord = labeled_coords [ n ]\n",
    "        #print ( coord [0] + x , coord [1] + y )\n",
    "        return ( coord [0] + x , coord [1] + y )\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"Provide x and y between 0 and 8\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeled_coord_of_patch ( n : int, x : int , y : int ):\n",
    "    \"\"\"\n",
    "        Returns coordinates (x,y) of image according to \n",
    "        label number n\n",
    "    \"\"\"\n",
    "    try:\n",
    "        labeled_coords = [(0,0), (0,1), (1,1), \n",
    "                          (1,0), (1,-1), (0,-1), \n",
    "                          (-1,-1), (-1,0), (-1,1) ]\n",
    "        coord = labeled_coords [ n ]\n",
    "        #print ( coord [0] + x , coord [1] + y )\n",
    "        return ( coord [0] + x , coord [1] + y )\n",
    "    except Exception as e:\n",
    "        raise ValueError(\"Provide x and y between 0 and 8\") from e\n",
    "\n",
    "def LBP( image : list, x : int, y : int ):\n",
    "    \"\"\"\n",
    "        Performs Local Binary Pattern.\n",
    "        Returns binary descriptor for patch whose center coordinates are given by input x and y. \n",
    "    \"\"\"\n",
    "    #print ( x , y )\n",
    "    return sum([(2 ** (i-1)) * \\\n",
    "    F1(image[labeled_coord_of_patch(i,x,y)[0]][labeled_coord_of_patch(i,x,y)[1]] \\\n",
    "       - image[labeled_coord_of_patch(0,x,y)[0]][labeled_coord_of_patch(0,x,y)[1]]) \\\n",
    "    for i in range ( 1 , 9 ) ])\n",
    "\n",
    "def LNDP ( image : list, x : int, y : int ):\n",
    "    \"\"\"\n",
    "        Performs Local Neighbourhood Pattern.\n",
    "        Returns binary descriptor for patch whose center coordinates are given by input x and y. \n",
    "    \"\"\"\n",
    "    def calculate_k1 ( n : int ):\n",
    "        m = n - 1\n",
    "        coords_for_In = labeled_coord_of_patch ( n , x,  y )\n",
    "\n",
    "        if n == 1:\n",
    "            coords_for_I8 = labeled_coord_of_patch ( 8 , x , y ) \n",
    "            #print ( coords_for_I8 )\n",
    "            return image [ coords_for_I8[0] ][ coords_for_I8[1] ] - image [ coords_for_In[0] ][ coords_for_In[1] ]\n",
    "        elif 2 <= n <= 8:\n",
    "            coords_for_Im = labeled_coord_of_patch ( m , x, y )\n",
    "            #print(coords_for_Im, coords_for_In)\n",
    "            return image [ coords_for_Im[0]][ coords_for_Im[1] ] - image [ coords_for_In[0]][ coords_for_In[1] ]\n",
    "\n",
    "    def calculate_k2 ( n : int ):\n",
    "        l = n + 1\n",
    "        coords_for_In = labeled_coord_of_patch ( n , x,  y )\n",
    "        if 1 <= n <= 7:\n",
    "            coords_for_Il = labeled_coord_of_patch ( l , x, y )\n",
    "            return image [ coords_for_Il[0] ][ coords_for_Il[1] ] - image [ coords_for_In[0] ][ coords_for_In[1] ]\n",
    "        elif n == 8:\n",
    "            coords_for_I1 = labeled_coord_of_patch ( 1 , x , y )\n",
    "            return image [ coords_for_I1[0] ][ coords_for_I1[1] ] - image [ coords_for_In[0] ][ coords_for_In[1] ]\n",
    "        \n",
    "    #print ( [ ( calculate_k1 ( i ) , calculate_k2 ( i ) ) for i in range ( 1, 9 )] )\n",
    "    \n",
    "    return sum([ 2 ** (i-1) * F3( calculate_k1 ( i ) , calculate_k2 ( i ) ) for i in range ( 1, 9 )])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector_of_image_using_local_pattern_descriptor ( image : list, LPD ):\n",
    "    \"\"\"\n",
    "        Gives feature vector for the image obtained by specified local pattern descriptor like \n",
    "        LBP ( Local Binary Pattern ) and LNDP ( Local Neighbourhood Pattern ).\n",
    "    \"\"\"\n",
    "    h , w = image.shape\n",
    "    padded_image = pad_image ( image )\n",
    "    LPD_of_each_pixel = [ LPD ( padded_image , \n",
    "                               x + 1, y + 1 ) \\\n",
    "                            for x in range ( h ) \\\n",
    "                            for y in range ( w ) ]\n",
    "    #print ( LPD_of_each_pixel )\n",
    "    hist, _ = np.histogram ( LPD_of_each_pixel, \n",
    "                            bins = 256, range = ( 0 , 256 ) )\n",
    "\n",
    "    return np.array(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_vec( data : list, min_val : int, max_val : int) -> list:\n",
    "    \"\"\"\n",
    "    Perform Min-Max normalization on the input data.\n",
    "\n",
    "    Parameters:\n",
    "    - data: A numpy array or list containing the data to be normalized.\n",
    "\n",
    "    Returns:\n",
    "    - normalized_data: The normalized data.\n",
    "    \"\"\"\n",
    "\n",
    "    normalized_data = (data - min_val) / (max_val - min_val)\n",
    "    return normalized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize ( x : int, min_val : int, max_val : int ) -> int:\n",
    "    return ( x - min_val ) / ( max_val - min_val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_normalized_feat_vect_of_image_using_LBP_LNDP ( image : list ):\n",
    "    \"\"\"\n",
    "        Gives feature vector for the image obtained by concatenating histograms of image obtained by\n",
    "        LBP (Local Binary Pattern) and LNDP (Local Neighbourhood Pattern).\n",
    "    \"\"\"\n",
    "    feat_vec = get_feature_vector_of_image_using_local_pattern_descriptor ( image, LBP ) +\\\n",
    "        get_feature_vector_of_image_using_local_pattern_descriptor ( image, LNDP )\n",
    "\n",
    "    return get_normalized_vec ( feat_vec, 0, 256 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dissimilarity_score_for_two_images ( first_image_path, second_image_path, \n",
    "                                            disimilarity_func =\\\n",
    "                                            get_histogram_dissimilarity_score ) -> float:\n",
    "    \"\"\"\n",
    "        Gives dissimilarity score between two images with the help of their feature vectors computed using LBP + LNDP\n",
    "        technique.\n",
    "    \"\"\"\n",
    "\n",
    "    first_image = cv2.imread ( first_image_path, 0 )\n",
    "    second_image = cv2.imread ( second_image_path, 0 )\n",
    "\n",
    "    first_image = cv2.resize ( first_image, ( 128 , 128 ) )\n",
    "    second_image = cv2.resize ( second_image, ( 128 , 128 ) )\n",
    "\n",
    "    first_image = first_image.astype ( np.int64 )\n",
    "    second_image = second_image.astype ( np.int64 )\n",
    "\n",
    "    dissimilarity_score =  disimilarity_func ( \n",
    "                get_normalized_feat_vect_of_image_using_LBP_LNDP( first_image ),\n",
    "                get_normalized_feat_vect_of_image_using_LBP_LNDP ( second_image ) )\n",
    "\n",
    "    return normalize ( dissimilarity_score, 0, 256 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blob(image : list, key_point : tuple , blob_size : tuple):\n",
    "    \"\"\"\n",
    "    Extracts a patch (blob) from the image centered at the key_point\n",
    "    with the specified blob_size (height, width).\n",
    "\n",
    "    Args:\n",
    "    - image: The input image.\n",
    "    - key_point: The key point (x, y) around which the blob is extracted.\n",
    "    - blob_size: The size of the blob in pixels (height, width).\n",
    "\n",
    "    Returns:\n",
    "    - blob_patch: The extracted patch (blob) from the image.\n",
    "    \"\"\"\n",
    "\n",
    "    kp_x, kp_y = int(key_point[0]), int(key_point[1])\n",
    "\n",
    "    blob_height, blob_width = blob_size\n",
    "\n",
    "    top_left_x = max(0, kp_x - blob_width // 2)\n",
    "    top_left_y = max(0, kp_y - blob_height // 2)\n",
    "\n",
    "    bottom_right_x = min(image.shape[1], kp_x + blob_width // 2)\n",
    "    bottom_right_y = min(image.shape[0], kp_y + blob_height // 2)\n",
    "\n",
    "    blob_patch = image[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
    "\n",
    "    return blob_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blob_sequence_at_point ( image : list, coord : tuple, \n",
    "                               blob_sizes = [ 10, 25, 50, 100 ] ) -> list:\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - image (list): Image from which squence of blobs is to be generated.\n",
    "    - coord (tuple): A tuple containing the (x, y) coordinate of the center of each blob.\n",
    "    - blob_sizes (list): Sizes of blobs of the sequence.\n",
    "    Returns:\n",
    "    - blob_sequence (list): A list containing the blobs.\n",
    "                            Each blob is represented as a square patch\n",
    "                            of the specified size with its center\n",
    "                            as given by the center_coordinates.\n",
    "    \"\"\"\n",
    "    return [ get_blob ( image, coord, ( blob_size, blob_size)) \\\n",
    "            for blob_size in blob_sizes ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"C:\\Users\\97433\\Mafkin_Robotics_FrontEnd\\VisualOdometry\\feature_extraction\\dataset\\images\\image_pair1\\image1.jpg\"\n",
    "image = cv2.imread ( image_path )\n",
    "coord = ( image.shape[0] // 2, image.shape[1] // 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matching_keypoints( first_image_path : list, second_image_path : list) -> list:\n",
    "    \"\"\" \n",
    "        Returns list of corresponding keypoints in both images sing ORB_FLANN feature matching.\n",
    "    \"\"\" \n",
    "    first_image = cv2.imread ( first_image_path , 0 )\n",
    "    second_image = cv2.imread ( second_image_path , 0 )\n",
    "    \n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    first_image_keypoints, first_descriptors = orb.detectAndCompute( first_image , None)\n",
    "    second_image_keypoints, second_descriptors = orb.detectAndCompute( second_image , None)\n",
    "\n",
    "    FLANN_INDEX_LSH = 6\n",
    "    index_params = dict(algorithm=FLANN_INDEX_LSH, table_number=6, key_size=12, multi_probe_level=1)\n",
    "    search_params = dict(checks=50)  \n",
    "\n",
    "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "    matches = flann.knnMatch( first_descriptors, second_descriptors, k=2)\n",
    "\n",
    "    good_matches = []\n",
    "    for match_pair in matches:\n",
    "        if len(match_pair) < 2:\n",
    "            continue\n",
    "        m , n = match_pair\n",
    "        if m.distance < 0.7 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    first_image_matched_keypoints = [ (int(first_image_keypoints[match.queryIdx].pt[0]) ,\n",
    "                                      int(first_image_keypoints[match.queryIdx].pt[1]))  \\\n",
    "                                    for match in good_matches]\n",
    "    second_image_matched_keypoints = [ (int(second_image_keypoints[match.trainIdx].pt[0]),\n",
    "                                        int(second_image_keypoints[match.trainIdx].pt[1])) \\\n",
    "                                      for match in good_matches]\n",
    "\n",
    "    return [ [keypoint, second_image_matched_keypoints[index] ] \\\n",
    "            for index,keypoint in enumerate ( first_image_matched_keypoints )]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image_path = r\"C:\\Users\\97433\\Mafkin_Robotics_FrontEnd\\VisualOdometry\\feature_extraction\\dataset\\images\\image_pair1\\image1.jpg\"\n",
    "second_image_path = r\"C:\\Users\\97433\\Mafkin_Robotics_FrontEnd\\VisualOdometry\\feature_extraction\\dataset\\images\\image_pair1\\image2.jpg\"\n",
    "#get_matching_keypoints ( first_image_path, second_image_path )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_matching_keypoints ( first_image_path : str, second_image_path : str ) -> list:\n",
    "    \"\"\"\n",
    "        Returns corresponding keypoints between two images.\n",
    "    \"\"\"\n",
    "    orb_keypoints = get_matching_keypoints ( first_image_path, second_image_path )\n",
    "    return [ [ first_image_keypoint[ 0 ], orb_keypoints [::-1] [ index ][ 1 ]] \\\n",
    "            for index, first_image_keypoint in enumerate ( orb_keypoints ) \n",
    "            if first_image_keypoint[ 1 ] != orb_keypoints [ ::-1 ][ index ][ 1 ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_matching_keypoints_blob_sequences ( folder_to_save : str, \n",
    "                                            image_pair_folder : str,\n",
    "                                            generate_keypoints_func : str,\n",
    "                                            generate_blob_sequence_func = get_blob_sequence_at_point,\n",
    "                                            extended_name_of_blob_sequence_folder = None) -> None:\n",
    "    \"\"\"\n",
    "        Functionality : \n",
    "        - Saves blob sequence consisting of blobs of various sizes having keypoints as center\n",
    "        for both images in the specified image pair folder. \n",
    "        \n",
    "        Parameters : \n",
    "        - folder_to_save : folder path to save blob_sequence.\n",
    "        - image_pair_folder : folder path for image pair.\n",
    "        - generate_keypoints_function : function used to generate keypoints.\n",
    "        - generate_blob_sequence_func : function used to generate blob sequence.\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.join ( folder_to_save ): os.makedirs ( folder_to_save )\n",
    "\n",
    "    first_image_path, second_image_path =\\\n",
    "        [ os.path.join ( image_pair_folder, image )\\\n",
    "        for image in os.listdir( image_pair_folder ) ]\n",
    "    \n",
    "    list_of_keypoints = generate_keypoints_func ( first_image_path, second_image_path )\n",
    "\n",
    "    first_image = cv2.imread ( first_image_path )\n",
    "    second_image = cv2.imread ( second_image_path )\n",
    "\n",
    "    blob_sequences_for_first_image = [ generate_blob_sequence_func ( first_image, keypoint[0] )\\\n",
    "                                      for keypoint in list_of_keypoints ]\n",
    "    \n",
    "    blob_sequences_for_second_image = [ generate_blob_sequence_func ( second_image, keypoint[1] )\\\n",
    "                                      for keypoint in list_of_keypoints ]\n",
    "\n",
    "    for index, blob_sequence in enumerate ( blob_sequences_for_first_image ):\n",
    "        blob_sequence_folder_name = \"blob_sequence_\" + str ( index ) + extended_name_of_blob_sequence_folder\n",
    "        blob_sequence_folder_path = os.path.join ( folder_to_save, blob_sequence_folder_name )\n",
    "        \n",
    "        if not os.path.exists ( blob_sequence_folder_path ): os.makedirs ( blob_sequence_folder_path )\n",
    "\n",
    "        first_image_blob_sequence_folder_path = os.path.join ( blob_sequence_folder_path, \"image1\" )\n",
    "        second_image_blob_sequence_folder_path = os.path.join ( blob_sequence_folder_path, \"image2\" )\n",
    "\n",
    "        if not os.path.exists ( first_image_blob_sequence_folder_path ): \n",
    "            os.makedirs ( first_image_blob_sequence_folder_path )\n",
    "\n",
    "        if not os.path.exists ( second_image_blob_sequence_folder_path ):\n",
    "            os.makedirs ( second_image_blob_sequence_folder_path )\n",
    "\n",
    "        for blob_index, blob_image in enumerate ( blob_sequence ):\n",
    "\n",
    "            blob_image_name = \"blob\" + str(blob_index) + \".jpg\"\n",
    "            \n",
    "            blob_image_path = os.path.join ( first_image_blob_sequence_folder_path, \n",
    "                                                        blob_image_name )\n",
    "            cv2.imwrite ( blob_image_path, blob_image )\n",
    "\n",
    "    \n",
    "        for blob_index, blob_image in enumerate ( blob_sequences_for_second_image [ index ] ):\n",
    "\n",
    "            blob_image_name = \"blob\" + str(blob_index) + \".jpg\"\n",
    "            \n",
    "            blob_image_path = os.path.join ( second_image_blob_sequence_folder_path, \n",
    "                                                        blob_image_name )\n",
    "            cv2.imwrite ( blob_image_path, blob_image )\n",
    "    print ( \"Done :)\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_save_matching_keypoints_blob_sequences ( folder_to_save : str, \n",
    "                                            folder_containing_image_pairs : str,\n",
    "                                            generate_keypoints_func : str,\n",
    "                                            generate_blob_sequence_func = get_blob_sequence_at_point ) -> None:\n",
    "    \"\"\"\n",
    "        Functionality : \n",
    "        - Saves blob sequence consisting of blobs of various sizes having specified keypoints as center\n",
    "        for images of image pairs in the specified folder. \n",
    "        \n",
    "        Parameters : \n",
    "        - folder_to_save : folder path to save blob_sequence.\n",
    "        - folder_containing_image_pairs : folder path containing image pairs.\n",
    "        - generate_keypoints_func : function used to generate keypoints.\n",
    "        - generate_blob_sequence_func : function used to generate blob sequence.\n",
    "    \"\"\"\n",
    "    if not os.path.exists ( folder_to_save ): os.makedirs ( folder_to_save )\n",
    "\n",
    "    for index, image_pair_folder in enumerate ( os.listdir ( folder_containing_image_pairs ) ):\n",
    "        \n",
    "        image_pair_folder_path = os.path.join ( folder_containing_image_pairs, image_pair_folder )\n",
    "        \n",
    "        # image_pair_folder_to_save_blob_sequence = \"image_pair\" + str(index)\n",
    "        \n",
    "        # image_pair_folder_to_save_blob_sequence_path = os.path.join ( folder_to_save,\n",
    "        #                                                             image_pair_folder_to_save_blob_sequence )\n",
    "        \n",
    "        # if not os.path.exists ( image_pair_folder_to_save_blob_sequence_path ):\n",
    "        #     os.makedirs ( image_pair_folder_to_save_blob_sequence_path )\n",
    "\n",
    "        extended_name_of_blob_sequence_folder = \"_image_pair\" + str(index)\n",
    "\n",
    "        save_matching_keypoints_blob_sequences ( folder_to_save = folder_to_save,\n",
    "                                                image_pair_folder = image_pair_folder_path,\n",
    "                                                generate_blob_sequence_func = generate_blob_sequence_func,\n",
    "                                                generate_keypoints_func = generate_keypoints_func,\n",
    "                                                extended_name_of_blob_sequence_folder = \\\n",
    "                                                    extended_name_of_blob_sequence_folder)\n",
    "\n",
    "    print ( \"Done :)\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset ( root_dir : str ) -> None:\n",
    "    \"\"\" \n",
    "        Balances dataset consisting of two classes by : \n",
    "        - removing additional files from class containing maximum number of files if difference \n",
    "        between number of files in both classes is less than 10. \n",
    "    \"\"\"\n",
    "    class_folder_paths = [ os.path.join ( root_dir, class_folder_name ) \\\n",
    "                          for class_folder_name in os.listdir ( root_dir ) ]\n",
    "    \n",
    "    class_folder_and_number_of_files = { class_folder_path : len(os.listdir( class_folder_path ))\\\n",
    "                                        for class_folder_path in class_folder_paths }\n",
    "    \n",
    "    sorted_class_folder_list = sorted ( class_folder_and_number_of_files, \n",
    "                                       key = class_folder_and_number_of_files.get )\n",
    "    \n",
    "    diff_in_number_of_files_in_classes = len ( os.listdir ( sorted_class_folder_list[1] ) ) - len ( os.listdir ( sorted_class_folder_list[0] ) )\n",
    "\n",
    "    if diff_in_number_of_files_in_classes < 20:\n",
    "        \n",
    "        majority_class_folder_path = sorted_class_folder_list [ 1 ]\n",
    "        \n",
    "        folders_in_majority_class =\\\n",
    "            [ os.path.join ( majority_class_folder_path, sub_folder ) \\\n",
    "            for sub_folder in os.listdir ( majority_class_folder_path )]\n",
    "    \n",
    "        folders_to_delete = random.sample(folders_in_majority_class, \n",
    "                                        min( diff_in_number_of_files_in_classes, \n",
    "                                            len(folders_in_majority_class)))\n",
    "\n",
    "        print ( len ( folders_to_delete ) )\n",
    "\n",
    "        for folder in folders_to_delete:\n",
    "            folder_path = os.path.join( majority_class_folder_path , folder)\n",
    "            shutil.rmtree ( folder_path )\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dissimilarity_scores_for_blob_sequences ( blob_sequence_path : str ) -> list:\n",
    "    \"\"\" \n",
    "        Returns a numpy array of dissimilarity scores between each blob in the sequence.\n",
    "    \"\"\"\n",
    "    image_paths = [ os.path.join ( blob_sequence_path, image_path )\\\n",
    "                    for image_path in os.listdir ( blob_sequence_path ) ]\n",
    "\n",
    "    blob_sequence_for_image1 = [ os.path.join ( image_paths[0], blob_path )\\\n",
    "                                    for blob_path in os.listdir( image_paths[0] ) ]\n",
    "    \n",
    "    blob_sequence_for_image2 = [ os.path.join ( image_paths[1], blob_path )\\\n",
    "                                    for blob_path in os.listdir( image_paths[1] ) ]\n",
    "    \n",
    "    return np.array ( [ get_dissimilarity_score_for_two_images ( blob1, blob_sequence_for_image2 [ index ] )\\\n",
    "                       for index, blob1 in enumerate ( blob_sequence_for_image1 )  ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_blob_sequence_dataset ( Dataset ):\n",
    "    \n",
    "    def __init__(self, root_dir : str, transform = None) -> None:\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def __len__ ( self ) -> int:\n",
    "        \n",
    "        class_folders = [ os.path.join ( self.root_dir, class_folder ) \\\n",
    "                        for class_folder in os.listdir ( self.root_dir ) ]\n",
    "        \n",
    "        return len ( os.listdir ( class_folders [ 0 ] ) ) + len ( os.listdir ( class_folders [ 1 ] ) )\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        class_folders = [ os.path.join ( self.root_dir, class_folder ) \\\n",
    "                        for class_folder in os.listdir ( self.root_dir ) ]\n",
    "        \n",
    "        blob_sequences = sorted([ os.path.join ( class_folder, blob_sequence_folder ) \\\n",
    "                            for class_folder in class_folders \\\n",
    "                            for blob_sequence_folder in os.listdir ( class_folder ) ])\n",
    "        \n",
    "        labels = [ 0 if \"dissimilar\" == blob_sequence.split(\"\\\\\")[-2] else 1 \\\n",
    "                for blob_sequence in blob_sequences  ]\n",
    "\n",
    "        return get_dissimilarity_scores_for_blob_sequences ( blob_sequences[ index ] ), labels [ index ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_training_and_testing_folders ( root_dir : str, train_test_split = 0.15 ) -> None:\n",
    "    \"\"\" \n",
    "        Splits the root directory into train and test folders.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_folder = os.path.join ( root_dir , \"train\" )\n",
    "    test_folder = os.path.join ( root_dir , \"test\" )\n",
    "\n",
    "    for class_folder in os.listdir ( root_dir ):\n",
    "\n",
    "        if class_folder == \"train\" or class_folder == \"test\":\n",
    "            continue\n",
    "\n",
    "        if not os.path.exists ( train_folder ): os.makedirs ( train_folder )\n",
    "        if not os.path.exists ( test_folder ): os.makedirs ( test_folder )\n",
    "\n",
    "        train_class_folder = os.path.join ( train_folder , class_folder )\n",
    "        test_class_folder = os.path.join ( test_folder , class_folder )\n",
    "\n",
    "        if not os.path.exists ( train_class_folder ):\n",
    "            os.makedirs ( train_class_folder )\n",
    "\n",
    "        if not os.path.exists ( test_class_folder ):\n",
    "            os.makedirs ( test_class_folder )\n",
    "\n",
    "        class_folder_path = os.path.join ( root_dir, class_folder )\n",
    "\n",
    "        blob_sequence_folder_paths = [ os.path.join ( class_folder_path, blob_sequence_folder ) \\\n",
    "                                    for blob_sequence_folder in os.listdir ( class_folder_path ) ]\n",
    "        \n",
    "        train_test_split_index = int ( len ( blob_sequence_folder_paths ) * train_test_split )\n",
    "        \n",
    "        test_data = blob_sequence_folder_paths [ : train_test_split_index ]\n",
    "        train_data = blob_sequence_folder_paths [ train_test_split_index : ]\n",
    "\n",
    "        for train_data_path in train_data:\n",
    "            shutil.move ( train_data_path , train_class_folder )\n",
    "        \n",
    "        for test_data_path in test_data:\n",
    "            shutil.move ( test_data_path , test_class_folder  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = r\"C:\\Users\\97433\\Mafkin_Robotics_FrontEnd\\VisualOdometry\\feature_extraction\\dataset_for_ANN\\train\"\n",
    "test_directory = r\"C:\\Users\\97433\\Mafkin_Robotics_FrontEnd\\VisualOdometry\\feature_extraction\\dataset_for_ANN\\test\"\n",
    "\n",
    "train_DS = custom_blob_sequence_dataset ( root_dir = train_directory )\n",
    "test_DS = custom_blob_sequence_dataset ( root_dir = test_directory )\n",
    "\n",
    "train_loader = DataLoader ( train_DS , batch_size = 4 , shuffle = True )\n",
    "test_loader = DataLoader ( test_DS , batch_size = 4 , shuffle = True  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceClassifier ( nn.Module ) :\n",
    "    def __init__ ( self ) :\n",
    "        super ( SequenceClassifier , self ).__init__()\n",
    "        self.fc1 = nn.Linear ( 4 , 16 ).float ()\n",
    "        self.fc2 = nn.Linear ( 16 , 8 ).float ()\n",
    "        self.fc3 = nn.Linear ( 8 , 1 ).float ()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu ( self.fc1( x ) )\n",
    "        x = torch.relu ( self.fc2( x ) )\n",
    "        x = torch.sigmoid( self.fc3( x ) )  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n",
      "torch.Size([4, 4]) torch.Size([4])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      9\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28mprint\u001b[39m ( inputs\u001b[38;5;241m.\u001b[39mshape, labels\u001b[38;5;241m.\u001b[39mshape )\n\u001b[0;32m     13\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mview( \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m , \u001b[38;5;241m1\u001b[39m )\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[31], line 24\u001b[0m, in \u001b[0;36mcustom_blob_sequence_dataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     17\u001b[0m blob_sequences \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m([ os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin ( class_folder, blob_sequence_folder ) \\\n\u001b[0;32m     18\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m class_folder \u001b[38;5;129;01min\u001b[39;00m class_folders \\\n\u001b[0;32m     19\u001b[0m                     \u001b[38;5;28;01mfor\u001b[39;00m blob_sequence_folder \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir ( class_folder ) ])\n\u001b[0;32m     21\u001b[0m labels \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdissimilar\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m==\u001b[39m blob_sequence\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m \\\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blob_sequence \u001b[38;5;129;01min\u001b[39;00m blob_sequences  ]\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_dissimilarity_scores_for_blob_sequences\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mblob_sequences\u001b[49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m, labels [ index ]\n",
      "Cell \u001b[1;32mIn[30], line 14\u001b[0m, in \u001b[0;36mget_dissimilarity_scores_for_blob_sequences\u001b[1;34m(blob_sequence_path)\u001b[0m\n\u001b[0;32m      8\u001b[0m blob_sequence_for_image1 \u001b[38;5;241m=\u001b[39m [ os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin ( image_paths[\u001b[38;5;241m0\u001b[39m], blob_path )\\\n\u001b[0;32m      9\u001b[0m                                 \u001b[38;5;28;01mfor\u001b[39;00m blob_path \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir( image_paths[\u001b[38;5;241m0\u001b[39m] ) ]\n\u001b[0;32m     11\u001b[0m blob_sequence_for_image2 \u001b[38;5;241m=\u001b[39m [ os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin ( image_paths[\u001b[38;5;241m1\u001b[39m], blob_path )\\\n\u001b[0;32m     12\u001b[0m                                 \u001b[38;5;28;01mfor\u001b[39;00m blob_path \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir( image_paths[\u001b[38;5;241m1\u001b[39m] ) ]\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray ( \u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_dissimilarity_score_for_two_images\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mblob1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblob_sequence_for_image2\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                   \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblob1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mblob_sequence_for_image1\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[43m]\u001b[49m )\n",
      "Cell \u001b[1;32mIn[30], line 14\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m blob_sequence_for_image1 \u001b[38;5;241m=\u001b[39m [ os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin ( image_paths[\u001b[38;5;241m0\u001b[39m], blob_path )\\\n\u001b[0;32m      9\u001b[0m                                 \u001b[38;5;28;01mfor\u001b[39;00m blob_path \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir( image_paths[\u001b[38;5;241m0\u001b[39m] ) ]\n\u001b[0;32m     11\u001b[0m blob_sequence_for_image2 \u001b[38;5;241m=\u001b[39m [ os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin ( image_paths[\u001b[38;5;241m1\u001b[39m], blob_path )\\\n\u001b[0;32m     12\u001b[0m                                 \u001b[38;5;28;01mfor\u001b[39;00m blob_path \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir( image_paths[\u001b[38;5;241m1\u001b[39m] ) ]\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray ( [ \u001b[43mget_dissimilarity_score_for_two_images\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mblob1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblob_sequence_for_image2\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\\\n\u001b[0;32m     15\u001b[0m                    \u001b[38;5;28;01mfor\u001b[39;00m index, blob1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m ( blob_sequence_for_image1 )  ] )\n",
      "Cell \u001b[1;32mIn[20], line 20\u001b[0m, in \u001b[0;36mget_dissimilarity_score_for_two_images\u001b[1;34m(first_image_path, second_image_path, disimilarity_func)\u001b[0m\n\u001b[0;32m     15\u001b[0m first_image \u001b[38;5;241m=\u001b[39m first_image\u001b[38;5;241m.\u001b[39mastype ( np\u001b[38;5;241m.\u001b[39mint64 )\n\u001b[0;32m     16\u001b[0m second_image \u001b[38;5;241m=\u001b[39m second_image\u001b[38;5;241m.\u001b[39mastype ( np\u001b[38;5;241m.\u001b[39mint64 )\n\u001b[0;32m     18\u001b[0m dissimilarity_score \u001b[38;5;241m=\u001b[39m  disimilarity_func ( \n\u001b[0;32m     19\u001b[0m             get_normalized_feat_vect_of_image_using_LBP_LNDP( first_image ),\n\u001b[1;32m---> 20\u001b[0m             \u001b[43mget_normalized_feat_vect_of_image_using_LBP_LNDP\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43msecond_image\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m )\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m normalize ( dissimilarity_score, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m256\u001b[39m )\n",
      "Cell \u001b[1;32mIn[19], line 7\u001b[0m, in \u001b[0;36mget_normalized_feat_vect_of_image_using_LBP_LNDP\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_normalized_feat_vect_of_image_using_LBP_LNDP\u001b[39m ( image : \u001b[38;5;28mlist\u001b[39m ):\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m        Gives feature vector for the image obtained by concatenating histograms of image obtained by\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03m        LBP (Local Binary Pattern) and LNDP (Local Neighbourhood Pattern).\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     feat_vec \u001b[38;5;241m=\u001b[39m get_feature_vector_of_image_using_local_pattern_descriptor ( image, LBP ) \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m----> 7\u001b[0m         \u001b[43mget_feature_vector_of_image_using_local_pattern_descriptor\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLNDP\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get_normalized_vec ( feat_vec, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m256\u001b[39m )\n",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m, in \u001b[0;36mget_feature_vector_of_image_using_local_pattern_descriptor\u001b[1;34m(image, LPD)\u001b[0m\n\u001b[0;32m      6\u001b[0m h , w \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m      7\u001b[0m padded_image \u001b[38;5;241m=\u001b[39m pad_image ( image )\n\u001b[1;32m----> 8\u001b[0m LPD_of_each_pixel \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[43mLPD\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadded_image\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#print ( LPD_of_each_pixel )\u001b[39;00m\n\u001b[0;32m     13\u001b[0m hist, _ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram ( LPD_of_each_pixel, \n\u001b[0;32m     14\u001b[0m                         bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m, \u001b[38;5;28mrange\u001b[39m \u001b[38;5;241m=\u001b[39m ( \u001b[38;5;241m0\u001b[39m , \u001b[38;5;241m256\u001b[39m ) )\n",
      "Cell \u001b[1;32mIn[16], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m h , w \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m      7\u001b[0m padded_image \u001b[38;5;241m=\u001b[39m pad_image ( image )\n\u001b[1;32m----> 8\u001b[0m LPD_of_each_pixel \u001b[38;5;241m=\u001b[39m [ \u001b[43mLPD\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadded_image\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m \\\n\u001b[0;32m     10\u001b[0m                         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m ( h ) \\\n\u001b[0;32m     11\u001b[0m                         \u001b[38;5;28;01mfor\u001b[39;00m y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m ( w ) ]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#print ( LPD_of_each_pixel )\u001b[39;00m\n\u001b[0;32m     13\u001b[0m hist, _ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhistogram ( LPD_of_each_pixel, \n\u001b[0;32m     14\u001b[0m                         bins \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m, \u001b[38;5;28mrange\u001b[39m \u001b[38;5;241m=\u001b[39m ( \u001b[38;5;241m0\u001b[39m , \u001b[38;5;241m256\u001b[39m ) )\n",
      "Cell \u001b[1;32mIn[15], line 57\u001b[0m, in \u001b[0;36mLNDP\u001b[1;34m(image, x, y)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m image [ coords_for_I1[\u001b[38;5;241m0\u001b[39m] ][ coords_for_I1[\u001b[38;5;241m1\u001b[39m] ] \u001b[38;5;241m-\u001b[39m image [ coords_for_In[\u001b[38;5;241m0\u001b[39m] ][ coords_for_In[\u001b[38;5;241m1\u001b[39m] ]\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#print ( [ ( calculate_k1 ( i ) , calculate_k2 ( i ) ) for i in range ( 1, 9 )] )\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43m[\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mF3\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculate_k1\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalculate_k2\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n",
      "Cell \u001b[1;32mIn[15], line 57\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m image [ coords_for_I1[\u001b[38;5;241m0\u001b[39m] ][ coords_for_I1[\u001b[38;5;241m1\u001b[39m] ] \u001b[38;5;241m-\u001b[39m image [ coords_for_In[\u001b[38;5;241m0\u001b[39m] ][ coords_for_In[\u001b[38;5;241m1\u001b[39m] ]\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#print ( [ ( calculate_k1 ( i ) , calculate_k2 ( i ) ) for i in range ( 1, 9 )] )\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msum\u001b[39m([ \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m F3( \u001b[43mcalculate_k1\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m , calculate_k2 ( i ) ) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m ( \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m9\u001b[39m )])\n",
      "Cell \u001b[1;32mIn[15], line 32\u001b[0m, in \u001b[0;36mLNDP.<locals>.calculate_k1\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mLNDP\u001b[39m ( image : \u001b[38;5;28mlist\u001b[39m, x : \u001b[38;5;28mint\u001b[39m, y : \u001b[38;5;28mint\u001b[39m ):\n\u001b[0;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m        Performs Local Neighbourhood Pattern.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;124;03m        Returns binary descriptor for patch whose center coordinates are given by input x and y. \u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_k1\u001b[39m ( n : \u001b[38;5;28mint\u001b[39m ):\n\u001b[0;32m     33\u001b[0m         m \u001b[38;5;241m=\u001b[39m n \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     34\u001b[0m         coords_for_In \u001b[38;5;241m=\u001b[39m labeled_coord_of_patch ( n , x,  y )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = SequenceClassifier()\n",
    "\n",
    "criterion = nn.BCELoss()  \n",
    "optimizer = optim.Adam ( model.parameters() , lr = 0.001 )\n",
    "\n",
    "epochs = 1000\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        print ( inputs.shape, labels.shape )\n",
    "\n",
    "        labels = labels.view( -1 , 1 ).float()\n",
    "        outputs = model ( inputs.float() )\n",
    "        loss = criterion( outputs , labels )\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss /= len(train_loader.dataset)\n",
    "    losses.append(epoch_loss)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}')\n",
    "\n",
    "plt.plot(losses, label='Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig('training_loss_plot.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
